---
title: "Southampton FC Transfermarkt Scraper"
author: "saintsnumbers"
output: github_document
date: 2019-07-28
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
# knitr::opts_chungit sk$set(echo = FALSE)

#libraries
library(tidyverse)
library(rvest)
library(magrittr)
theme_set(theme_bw())

#delete environment variables
rm(list=ls())
```

## Scraping Southampton FC Transfermarkt data

### Plan

* Load the webpage containing the data.
* Locate the data within the page and extract it.
* Organise the data into a dataframe.
* Load more data.
* Do stats on it.

### Load the webpage

* [**Southampton FC Transfermarkt** (detailed)](https://www.transfermarkt.co.uk/southampton-fc/kader/verein/180/saison_id/2019/plus/1)
* [**Southampton FC Transfermarkt** Premier League 18/19 (detailed)](https://www.transfermarkt.co.uk/southampton-fc/leistungsdaten/verein/180/reldata/GB1%262018/plus/1)
* [Page used in the example](https://www.transfermarkt.co.uk/manchester-city/startseite/verein/281/saison_id/2019)

```{r load}
squad_url <- "https://www.transfermarkt.co.uk/southampton-fc/kader/verein/180/saison_id/2019/plus/1"
season19_url <- "https://www.transfermarkt.co.uk/southampton-fc/leistungsdaten/verein/180/reldata/GB1%262018/plus/1"
squad_scraped <- read_html("https://www.transfermarkt.co.uk/southampton-fc/kader/verein/180/saison_id/2019/plus/1")
season19_scraped <- read_html("https://www.transfermarkt.co.uk/southampton-fc/leistungsdaten/verein/180/reldata/GB1%262018/plus/1")
```

### Extract the data

Done | Needs tidying | Not done
-- | -- | --
Name | Height |
Squad Number | Foot | 18/19 Stats
Position | |
DOB/Age | |
Contract | |
Joined | |

```{r extract}
player_names_raw <- squad_scraped %>%
  html_nodes(".spielprofil_tooltip") %>%
  html_text()

player_names <- player_names_raw[seq(1,length(player_names_raw),2)] #duplicated - take odd numbered data only

player_numbers <- squad_scraped %>%
  html_nodes(".rn_nummer") %>%
  html_text
player_numbers[player_numbers == "-"] <- NA

player_position <- squad_scraped %>%
  html_nodes(".inline-table tr:nth-child(2) td") %>%
  html_text

player_dob <- squad_scraped %>%
  html_nodes("#yw1 td:nth-child(3)") %>%
  html_text

player_height <- squad_scraped %>%
  html_nodes("td:nth-child(5)") %>%
  html_text

player_foot <- squad_scraped %>%
  html_nodes("td:nth-child(6)") %>%
  html_text

player_joined <- squad_scraped %>%
  html_nodes("td:nth-child(7)") %>%
  html_text

player_contract <- squad_scraped %>%
  html_nodes("td:nth-child(9)") %>%
  html_text
```

### Tidy data

```{r tidy}
player_data <- data.frame(Name = player_names, Number = player_numbers, Position = player_position, DoB = player_dob, Height = player_height, Foot = player_foot, Joined = player_joined, Contract = player_contract)

player_data %<>%
  as_tibble

player_data %>%
  head(8)
```


### To do

* Get better html selectors process to avoid having to remove duplicated data
* Improve format of data as in table above
* Scrape new web pages

#http://www.fantasyfutopia.com/python-for-fantasy-football-getting-and-cleaning-data/
#https://github.com/ewenme/understatr
#https://www.daolf.com/posts/avoiding-being-blocked-while-scraping-ultimate-guide/

```{r}
# ggplot(player_data) + geom_point(aes(x=Name,y=as.integer(Number)))
```

